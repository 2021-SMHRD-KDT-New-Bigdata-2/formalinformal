{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 코랩에서 사용한 스켈레탈 코드\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np \n",
    "import skimage.io as io \n",
    "import matplotlib.pyplot as plt \n",
    "import pylab\n",
    "import json\n",
    "\n",
    "NthPerson = '001'\n",
    "NthFrame = '0121'\n",
    "\n",
    "# imgPath = f'/content/drive/MyDrive/golf/20201210_General_114_DOC_A_M30_MM_{NthPerson}_{NthFrame}.jpg'\n",
    "# annPath = f'/content/drive/MyDrive/Colab Notebooks/HRD/golf_coco/20200612_General_003_DOS_P_F20_MM/20200612_General_003_DOS_P_F20_MM_{NthPerson}_{NthFrame}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model object from the keypointrcnn_resnet50_fpn class\n",
    "model = torchvision.models.detection.keypointrcnn_resnet50_fpn(pretrained=True)\n",
    "# call the eval() method to prepare the model for inference mode.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the list of keypoints.\n",
    "keypoints = ['nose','left_eye','right_eye','left_ear','right_ear','left_shoulder','right_shoulder','left_elbow',\n",
    "                'right_elbow','left_wrist','right_wrist','left_hip','right_hip','left_knee', 'right_knee', 'left_ankle','right_ankle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the limbs\n",
    "def get_limbs_from_keypoints(keypoints):\n",
    "    limbs = [       \n",
    "        [keypoints.index('right_eye'), keypoints.index('nose')],\n",
    "        [keypoints.index('right_eye'), keypoints.index('right_ear')],\n",
    "        [keypoints.index('left_eye'), keypoints.index('nose')],\n",
    "        [keypoints.index('left_eye'), keypoints.index('left_ear')],\n",
    "        [keypoints.index('right_shoulder'), keypoints.index('right_elbow')],\n",
    "        [keypoints.index('right_elbow'), keypoints.index('right_wrist')],\n",
    "        [keypoints.index('left_shoulder'), keypoints.index('left_elbow')],\n",
    "        [keypoints.index('left_elbow'), keypoints.index('left_wrist')],\n",
    "        [keypoints.index('right_hip'), keypoints.index('right_knee')],\n",
    "        [keypoints.index('right_knee'), keypoints.index('right_ankle')],\n",
    "        [keypoints.index('left_hip'), keypoints.index('left_knee')],\n",
    "        [keypoints.index('left_knee'), keypoints.index('left_ankle')],\n",
    "        [keypoints.index('right_shoulder'), keypoints.index('left_shoulder')],\n",
    "        [keypoints.index('right_hip'), keypoints.index('left_hip')],\n",
    "        [keypoints.index('right_shoulder'), keypoints.index('right_hip')],\n",
    "        [keypoints.index('left_shoulder'), keypoints.index('left_hip')]\n",
    "        ]\n",
    "    return limbs\n",
    "\n",
    "\n",
    "limbs = get_limbs_from_keypoints(keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "\n",
    "# Read the image using opencv \n",
    "img = cv2.imread(imgPath)\n",
    "\n",
    "# preprocess the input image\n",
    "transform = T.Compose([T.ToTensor()])\n",
    "img_tensor = transform(img)\n",
    "\n",
    "# forward-pass the model\n",
    "# the input is a list, hence the output will also be a list\n",
    "output = model([img_tensor])[0]\n",
    "\n",
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[\"keypoints\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "  y= output[\"keypoints\"][0, :2]\n",
    "  print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= output[\"keypoints\"][0, :2]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(output[\"keypoints\"]), torch.min(output[\"keypoints\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "keypoints_img = draw_keypoints_per_person(img, output[\"keypoints\"], output[\"keypoints_scores\"], output[\"scores\"],keypoint_threshold=2)\n",
    "\n",
    "cv2.imwrite(\"output/keypoints-img.jpg\", keypoints_img)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(keypoints_img[:, :, ::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints_per_person(img, all_keypoints, all_scores, confs, keypoint_threshold=2, conf_threshold=0.9):\n",
    "    # initialize a set of colors from the rainbow spectrum\n",
    "    cmap = plt.get_cmap('rainbow')\n",
    "    # create a copy of the image\n",
    "    img_copy = img.copy()\n",
    "    # pick a set of N color-ids from the spectrum\n",
    "    color_id = np.arange(1,255, 255//len(all_keypoints)).tolist()[::-1]\n",
    "    # iterate for every person detected\n",
    "    for person_id in range(len(all_keypoints)):\n",
    "      # check the confidence score of the detected person\n",
    "      if confs[person_id]>conf_threshold:\n",
    "        # grab the keypoint-locations for the detected person\n",
    "        keypoints = all_keypoints[person_id, ...]\n",
    "        # grab the keypoint-scores for the keypoints\n",
    "        scores = all_scores[person_id, ...]\n",
    "        # iterate for every keypoint-score\n",
    "        for kp in range(len(scores)):\n",
    "            # check the confidence score of detected keypoint\n",
    "            if scores[kp]>keypoint_threshold:\n",
    "                # convert the keypoint float-array to a python-list of intergers\n",
    "                keypoint = tuple(map(int, keypoints[kp, :2].detach().numpy().tolist()))\n",
    "                # pick the color at the specific color-id\n",
    "                color = tuple(np.asarray(cmap(color_id[person_id])[:-1])*255)\n",
    "                # draw a cirle over the keypoint location\n",
    "                cv2.circle(img_copy, keypoint, 10, color, -1)\n",
    "\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay the skeleton in the detected person\n",
    "skeletal_img = draw_skeleton_per_person(img, output[\"keypoints\"], output[\"keypoints_scores\"], output[\"scores\"],keypoint_threshold=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(skeletal_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
